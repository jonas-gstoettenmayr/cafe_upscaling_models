{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c34ae95b",
   "metadata": {},
   "source": [
    "# Final model\n",
    "Here the best combination of predictor and dataset features will be determined and validated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13021c1e",
   "metadata": {},
   "source": [
    "## Model selection with feature combinations\n",
    "We evaluate multiple feature sets (baseline, holidays, Fourier, trend, and their combination) together with different predictors. Each predictor is fine-tuned via a small hyperparameter grid, and the best-performing combination on the validation split is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61936b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from statsforecast.core import StatsForecast\n",
    "from statsforecast.models import AutoARIMA, AutoETS, SeasonalNaive\n",
    "from statsforecast.models import AutoARIMA, AutoETS, SeasonalNaive\n",
    "import inspect\n",
    "\n",
    "DATA_DIR = Path(\"..\") / \"data\" / \"processed_data\"\n",
    "FEATURE_KEYS = [\"none\", \"holidays\", \"fourier\", \"trend\", \"fourier+trend+holidays\"]\n",
    "SPLITS = [\"train\", \"val\"]\n",
    "FREQ = \"D\"\n",
    "\n",
    "def load_feature_sets():\n",
    "    features = {k: {} for k in FEATURE_KEYS}\n",
    "    future = {k: {} for k in FEATURE_KEYS}\n",
    "    for key in FEATURE_KEYS:\n",
    "        for split in SPLITS:\n",
    "            path = DATA_DIR / f\"{key}_{split}.parquet\"\n",
    "            features[key][split] = pl.read_parquet(path) if path.exists() else None\n",
    "            future_path = DATA_DIR / f\"{key}_{split}_future.parquet\"\n",
    "            future[key][split] = pl.read_parquet(future_path) if future_path.exists() else None\n",
    "    return features, future\n",
    "\n",
    "def prepare_target(df: pl.DataFrame) -> pd.DataFrame:\n",
    "    return df.select([\"unique_id\", \"ds\", \"y\"]).to_pandas()\n",
    "\n",
    "features, features_future = load_feature_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a8793b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3c56ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcce2c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_horizon(df_future: pl.DataFrame | None, val_df: pl.DataFrame) -> int:\n",
    "    if df_future is not None:\n",
    "        first_id = df_future[\"unique_id\"][0]\n",
    "        return df_future.filter(pl.col(\"unique_id\") == first_id).height\n",
    "    first_id = val_df[\"unique_id\"][0]\n",
    "    return val_df.filter(pl.col(\"unique_id\") == first_id).height\n",
    "\n",
    "MODEL_GRID = {\n",
    "    \"AutoARIMA\": {\n",
    "        \"constructor\": AutoARIMA,\n",
    "        \"params\": {\n",
    "            \"season_length\": [7],\n",
    "            \"stepwise\": [True],\n",
    "            \"approximation\": [True, False],\n",
    "        },\n",
    "    },\n",
    "    \"AutoETS\": {\n",
    "        \"constructor\": AutoETS,\n",
    "        \"params\": {\n",
    "            \"season_length\": [7],\n",
    "            \"model\": [\"ZZZ\"],\n",
    "        },\n",
    "    },\n",
    "    \"SeasonalNaive\": {\n",
    "        \"constructor\": SeasonalNaive,\n",
    "        \"params\": {\n",
    "            \"season_length\": [7, 14],\n",
    "        },\n",
    "    },\n",
    "    # RandomForestRegressor handled separately (not a StatsForecast model)\n",
    "    \"RandomForestRegressor\": {\n",
    "        \"constructor\": RandomForestRegressor,\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [200, 400, 600],\n",
    "            \"max_depth\": [None, 10, 20],\n",
    "            \"random_state\": [42],\n",
    "            \"n_jobs\": [-1],\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def _fit_with_exog(sf: StatsForecast, df: pd.DataFrame):\n",
    "    return sf.fit(df=df)\n",
    "\n",
    "def _predict_with_exog(fitted: StatsForecast, h: int):\n",
    "    return fitted.predict(h=h)\n",
    "\n",
    "def evaluate_feature_model(feature_key: str):\n",
    "    train = features[feature_key].get(\"train\")\n",
    "    val = features[feature_key].get(\"val\")\n",
    "    val_future = features_future[feature_key].get(\"val\")\n",
    "    if train is None or val is None:\n",
    "        return []\n",
    "    y_train = prepare_target(train)\n",
    "    y_val = prepare_target(val)\n",
    "    h = get_horizon(val_future, val)\n",
    "\n",
    "    results = []\n",
    "    for model_name, cfg in MODEL_GRID.items():\n",
    "        for params in ParameterGrid(cfg[\"params\"]):\n",
    "            # RandomForest branch uses all non-(unique_id, ds, y) columns already in the dataset\n",
    "            if model_name == \"RandomForestRegressor\":\n",
    "                train_df = train.to_pandas()\n",
    "                val_df = val.to_pandas()\n",
    "                feature_cols = [c for c in train_df.columns if c not in [\"unique_id\", \"ds\", \"y\"]]\n",
    "                if not feature_cols:\n",
    "                    print(f\"Skipping RandomForest for {feature_key}: no feature columns available\")\n",
    "                    continue\n",
    "\n",
    "                train_df = train_df[[\"unique_id\", \"ds\", \"y\", *feature_cols]].fillna(\"\")\n",
    "                val_df = val_df[[\"unique_id\", \"ds\", \"y\", *feature_cols]].fillna(\"\")\n",
    "\n",
    "                cat_cols = [c for c in feature_cols if train_df[c].dtype == \"object\"]\n",
    "                train_X = pd.get_dummies(train_df[feature_cols], columns=cat_cols, drop_first=False)\n",
    "                val_X = pd.get_dummies(val_df[feature_cols], columns=cat_cols, drop_first=False)\n",
    "\n",
    "                cols = sorted(set(train_X.columns) | set(val_X.columns))\n",
    "                train_X = train_X.reindex(columns=cols, fill_value=0)\n",
    "                val_X = val_X.reindex(columns=cols, fill_value=0)\n",
    "\n",
    "                rf = cfg[\"constructor\"](**params)\n",
    "                rf.fit(train_X, train_df[\"y\"])\n",
    "                preds = rf.predict(val_X)\n",
    "                merged = val_df.copy()\n",
    "                merged[\"yhat\"] = preds\n",
    "                mae = mean_absolute_error(merged[\"y\"], merged[\"yhat\"])\n",
    "                rmse = root_mean_squared_error(merged[\"y\"], merged[\"yhat\"])\n",
    "                smape = np.mean(200 * np.abs(merged[\"yhat\"] - merged[\"y\"]) / (np.abs(merged[\"y\"]) + np.abs(merged[\"yhat\"]) + 1e-8))\n",
    "                r2 = r2_score(merged[\"y\"], merged[\"yhat\"])\n",
    "                results.append({\n",
    "                    \"feature_set\": feature_key,\n",
    "                    \"model\": model_name,\n",
    "                    \"params\": params,\n",
    "                    \"used_exog\": True,\n",
    "                    \"mae\": mae,\n",
    "                    \"rmse\": rmse,\n",
    "                    \"smape\": smape,\n",
    "                    \"r2\": r2,\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            model = cfg[\"constructor\"](**params)\n",
    "            sf = StatsForecast(models=[model], freq=FREQ, n_jobs=-1)\n",
    "            fitted = _fit_with_exog(sf, y_train)\n",
    "            fcst = _predict_with_exog(fitted, h)\n",
    "            yhat_col = [c for c in fcst.columns if c not in (\"unique_id\", \"ds\")][0]\n",
    "            preds = fcst.rename(columns={yhat_col: \"yhat\"})\n",
    "            merged = y_val.merge(preds, on=[\"unique_id\", \"ds\"], how=\"inner\")\n",
    "            mae = mean_absolute_error(merged[\"y\"], merged[\"yhat\"])\n",
    "            rmse = root_mean_squared_error(merged[\"y\"], merged[\"yhat\"])\n",
    "            smape = np.mean(200 * np.abs(merged[\"yhat\"] - merged[\"y\"]) / (np.abs(merged[\"y\"]) + np.abs(merged[\"yhat\"]) + 1e-8))\n",
    "            r2 = r2_score(merged[\"y\"], merged[\"yhat\"])\n",
    "            results.append({\n",
    "                \"feature_set\": feature_key,\n",
    "                \"model\": model_name,\n",
    "                \"params\": params,\n",
    "                \"used_exog\": False,\n",
    "                \"mae\": mae,\n",
    "                \"rmse\": rmse,\n",
    "                \"smape\": smape,\n",
    "                \"r2\": r2,\n",
    "            })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83ab9149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping RandomForest for none: no feature columns available\n",
      "Skipping RandomForest for none: no feature columns available\n",
      "Skipping RandomForest for none: no feature columns available\n",
      "Skipping RandomForest for none: no feature columns available\n",
      "Skipping RandomForest for none: no feature columns available\n",
      "Skipping RandomForest for none: no feature columns available\n",
      "Skipping RandomForest for none: no feature columns available\n",
      "Skipping RandomForest for none: no feature columns available\n",
      "Skipping RandomForest for none: no feature columns available\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_set</th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>used_exog</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>smape</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>none</td>\n",
       "      <td>AutoETS</td>\n",
       "      <td>{'model': 'ZZZ', 'season_length': 7}</td>\n",
       "      <td>False</td>\n",
       "      <td>78.507702</td>\n",
       "      <td>169.319382</td>\n",
       "      <td>19.019246</td>\n",
       "      <td>0.980389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>holidays</td>\n",
       "      <td>AutoETS</td>\n",
       "      <td>{'model': 'ZZZ', 'season_length': 7}</td>\n",
       "      <td>False</td>\n",
       "      <td>78.507702</td>\n",
       "      <td>169.319382</td>\n",
       "      <td>19.019246</td>\n",
       "      <td>0.980389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fourier</td>\n",
       "      <td>AutoETS</td>\n",
       "      <td>{'model': 'ZZZ', 'season_length': 7}</td>\n",
       "      <td>False</td>\n",
       "      <td>78.507702</td>\n",
       "      <td>169.319382</td>\n",
       "      <td>19.019246</td>\n",
       "      <td>0.980389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trend</td>\n",
       "      <td>AutoETS</td>\n",
       "      <td>{'model': 'ZZZ', 'season_length': 7}</td>\n",
       "      <td>False</td>\n",
       "      <td>78.507702</td>\n",
       "      <td>169.319382</td>\n",
       "      <td>19.019246</td>\n",
       "      <td>0.980389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fourier+trend+holidays</td>\n",
       "      <td>AutoETS</td>\n",
       "      <td>{'model': 'ZZZ', 'season_length': 7}</td>\n",
       "      <td>False</td>\n",
       "      <td>78.507702</td>\n",
       "      <td>169.319382</td>\n",
       "      <td>19.019246</td>\n",
       "      <td>0.980389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>none</td>\n",
       "      <td>AutoARIMA</td>\n",
       "      <td>{'approximation': True, 'season_length': 7, 's...</td>\n",
       "      <td>False</td>\n",
       "      <td>81.335207</td>\n",
       "      <td>174.744147</td>\n",
       "      <td>19.149107</td>\n",
       "      <td>0.979113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>holidays</td>\n",
       "      <td>AutoARIMA</td>\n",
       "      <td>{'approximation': True, 'season_length': 7, 's...</td>\n",
       "      <td>False</td>\n",
       "      <td>81.335207</td>\n",
       "      <td>174.744147</td>\n",
       "      <td>19.149107</td>\n",
       "      <td>0.979113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fourier</td>\n",
       "      <td>AutoARIMA</td>\n",
       "      <td>{'approximation': True, 'season_length': 7, 's...</td>\n",
       "      <td>False</td>\n",
       "      <td>81.335207</td>\n",
       "      <td>174.744147</td>\n",
       "      <td>19.149107</td>\n",
       "      <td>0.979113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>trend</td>\n",
       "      <td>AutoARIMA</td>\n",
       "      <td>{'approximation': True, 'season_length': 7, 's...</td>\n",
       "      <td>False</td>\n",
       "      <td>81.335207</td>\n",
       "      <td>174.744147</td>\n",
       "      <td>19.149107</td>\n",
       "      <td>0.979113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fourier+trend+holidays</td>\n",
       "      <td>AutoARIMA</td>\n",
       "      <td>{'approximation': True, 'season_length': 7, 's...</td>\n",
       "      <td>False</td>\n",
       "      <td>81.335207</td>\n",
       "      <td>174.744147</td>\n",
       "      <td>19.149107</td>\n",
       "      <td>0.979113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature_set      model  \\\n",
       "0                    none    AutoETS   \n",
       "1                holidays    AutoETS   \n",
       "2                 fourier    AutoETS   \n",
       "3                   trend    AutoETS   \n",
       "4  fourier+trend+holidays    AutoETS   \n",
       "5                    none  AutoARIMA   \n",
       "6                holidays  AutoARIMA   \n",
       "7                 fourier  AutoARIMA   \n",
       "8                   trend  AutoARIMA   \n",
       "9  fourier+trend+holidays  AutoARIMA   \n",
       "\n",
       "                                              params  used_exog        mae  \\\n",
       "0               {'model': 'ZZZ', 'season_length': 7}      False  78.507702   \n",
       "1               {'model': 'ZZZ', 'season_length': 7}      False  78.507702   \n",
       "2               {'model': 'ZZZ', 'season_length': 7}      False  78.507702   \n",
       "3               {'model': 'ZZZ', 'season_length': 7}      False  78.507702   \n",
       "4               {'model': 'ZZZ', 'season_length': 7}      False  78.507702   \n",
       "5  {'approximation': True, 'season_length': 7, 's...      False  81.335207   \n",
       "6  {'approximation': True, 'season_length': 7, 's...      False  81.335207   \n",
       "7  {'approximation': True, 'season_length': 7, 's...      False  81.335207   \n",
       "8  {'approximation': True, 'season_length': 7, 's...      False  81.335207   \n",
       "9  {'approximation': True, 'season_length': 7, 's...      False  81.335207   \n",
       "\n",
       "         rmse      smape        r2  \n",
       "0  169.319382  19.019246  0.980389  \n",
       "1  169.319382  19.019246  0.980389  \n",
       "2  169.319382  19.019246  0.980389  \n",
       "3  169.319382  19.019246  0.980389  \n",
       "4  169.319382  19.019246  0.980389  \n",
       "5  174.744147  19.149107  0.979113  \n",
       "6  174.744147  19.149107  0.979113  \n",
       "7  174.744147  19.149107  0.979113  \n",
       "8  174.744147  19.149107  0.979113  \n",
       "9  174.744147  19.149107  0.979113  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "feature_set                                    none\n",
       "model                                       AutoETS\n",
       "params         {'model': 'ZZZ', 'season_length': 7}\n",
       "used_exog                                     False\n",
       "mae                                       78.507702\n",
       "rmse                                     169.319382\n",
       "smape                                     19.019246\n",
       "r2                                         0.980389\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results: list[dict] = []\n",
    "for feature_key in FEATURE_KEYS:\n",
    "    all_results.extend(evaluate_feature_model(feature_key))\n",
    "\n",
    "if not all_results:\n",
    "    raise RuntimeError(\"No feature/model results were produced. Ensure processed parquet files exist.\")\n",
    "\n",
    "results_df = pd.DataFrame(all_results).sort_values([\"rmse\", \"mae\"]).reset_index(drop=True)\n",
    "display(results_df.head(10))\n",
    "\n",
    "best_combo = results_df.iloc[0]\n",
    "best_combo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572e25bd",
   "metadata": {},
   "source": [
    "## Test set evaluation\n",
    "Load test split, retrain best model on train+val, and generate predictions against baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e312469c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: AutoETS with none features\n",
      "Params: {'model': 'ZZZ', 'season_length': 7}\n",
      "Used exog: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'val', 'test'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load test split\n",
    "SPLITS_TEST = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "def load_all_splits(feature_key: str):\n",
    "    splits_data = {}\n",
    "    futures_data = {}\n",
    "    for split in SPLITS_TEST:\n",
    "        path = DATA_DIR / f\"{feature_key}_{split}.parquet\"\n",
    "        splits_data[split] = pl.read_parquet(path) if path.exists() else None\n",
    "        future_path = DATA_DIR / f\"{feature_key}_{split}_future.parquet\"\n",
    "        futures_data[split] = pl.read_parquet(future_path) if future_path.exists() else None\n",
    "    return splits_data, futures_data\n",
    "\n",
    "best_feature = best_combo[\"feature_set\"]\n",
    "best_model_name = best_combo[\"model\"]\n",
    "best_params = best_combo[\"params\"]\n",
    "used_exog = best_combo[\"used_exog\"]\n",
    "\n",
    "print(f\"Best: {best_model_name} with {best_feature} features\")\n",
    "print(f\"Params: {best_params}\")\n",
    "print(f\"Used exog: {used_exog}\")\n",
    "\n",
    "splits, futures = load_all_splits(best_feature)\n",
    "splits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41cd50ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train+Val shape: (19490, 3)\n",
      "Test shape: (310, 3)\n",
      "Test horizon: 31\n",
      "Feature columns available: []\n"
     ]
    }
   ],
   "source": [
    "# Combine train+val for final training\n",
    "y_train_val = pd.concat([\n",
    "    prepare_target(splits[\"train\"]),\n",
    "    prepare_target(splits[\"val\"])\n",
    "], ignore_index=True).sort_values([\"unique_id\", \"ds\"]).reset_index(drop=True)\n",
    "\n",
    "y_test = prepare_target(splits[\"test\"])\n",
    "\n",
    "# Feature columns already present in dataset (non-unique_id/ds/y)\n",
    "train_full = splits[\"train\"].to_pandas()\n",
    "val_full = splits[\"val\"].to_pandas()\n",
    "test_full = splits[\"test\"].to_pandas()\n",
    "feature_cols = [c for c in train_full.columns if c not in [\"unique_id\", \"ds\", \"y\"]]\n",
    "\n",
    "X_train_val = None\n",
    "X_test_future = None\n",
    "if feature_cols:\n",
    "    X_train_val = pd.concat([\n",
    "        train_full[[\"unique_id\", \"ds\", *feature_cols]],\n",
    "        val_full[[\"unique_id\", \"ds\", *feature_cols]]\n",
    "    ], ignore_index=True).sort_values([\"unique_id\", \"ds\"]).reset_index(drop=True).fillna(0)\n",
    "    X_test_future = test_full[[\"unique_id\", \"ds\", *feature_cols]].sort_values([\"unique_id\", \"ds\"]).reset_index(drop=True).fillna(0)\n",
    "\n",
    "h_test = get_horizon(futures[\"test\"], splits[\"test\"])\n",
    "print(f\"Train+Val shape: {y_train_val.shape}\")\n",
    "print(f\"Test shape: {y_test.shape}\")\n",
    "print(f\"Test horizon: {h_test}\")\n",
    "print(f\"Feature columns available: {feature_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f637439b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Baseline and best model trained\n"
     ]
    }
   ],
   "source": [
    "# Train baseline (SeasonalNaive 7-day)\n",
    "baseline_model = SeasonalNaive(season_length=7)\n",
    "sf_baseline = StatsForecast(models=[baseline_model], freq=FREQ, n_jobs=-1)\n",
    "sf_baseline.fit(df=y_train_val)\n",
    "fcst_baseline = sf_baseline.predict(h=h_test)\n",
    "\n",
    "baseline_col = [c for c in fcst_baseline.columns if c not in (\"unique_id\", \"ds\")][0]\n",
    "fcst_baseline = fcst_baseline.rename(columns={baseline_col: \"baseline_pred\"})\n",
    "\n",
    "# Train best model\n",
    "best_model_constructor = MODEL_GRID[best_model_name][\"constructor\"]\n",
    "best_model = best_model_constructor(**best_params)\n",
    "\n",
    "if best_model_name == \"RandomForestRegressor\":\n",
    "    if X_train_val is None or X_test_future is None:\n",
    "        raise RuntimeError(\"RandomForestRegressor selected but no feature columns are available.\")\n",
    "    train_df = y_train_val.merge(X_train_val, on=[\"unique_id\", \"ds\"], how=\"left\").fillna(0)\n",
    "    test_df = y_test.merge(X_test_future, on=[\"unique_id\", \"ds\"], how=\"left\").fillna(0)\n",
    "    feature_cols_rf = [c for c in train_df.columns if c not in [\"unique_id\", \"ds\", \"y\"]]\n",
    "    best_model.fit(train_df[feature_cols_rf], train_df[\"y\"])\n",
    "    test_preds = best_model.predict(test_df[feature_cols_rf])\n",
    "    fcst_best = test_df[[\"unique_id\", \"ds\"]].copy()\n",
    "    fcst_best[\"best_pred\"] = test_preds\n",
    "else:\n",
    "    sf_best = StatsForecast(models=[best_model], freq=FREQ, n_jobs=-1)\n",
    "    fitted_best = sf_best.fit(df=y_train_val)\n",
    "    fcst_best = fitted_best.predict(h=h_test)\n",
    "    best_col = [c for c in fcst_best.columns if c not in (\"unique_id\", \"ds\")][0]\n",
    "    fcst_best = fcst_best.rename(columns={best_col: \"best_pred\"})\n",
    "\n",
    "print(\"✓ Baseline and best model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eafdad59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>feature_set</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>smape</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline (SeasonalNaive-7)</td>\n",
       "      <td>none</td>\n",
       "      <td>100.566129</td>\n",
       "      <td>164.751355</td>\n",
       "      <td>24.294597</td>\n",
       "      <td>0.976751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Best (AutoETS)</td>\n",
       "      <td>none</td>\n",
       "      <td>86.852207</td>\n",
       "      <td>153.463049</td>\n",
       "      <td>17.512230</td>\n",
       "      <td>0.979828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model feature_set         mae        rmse      smape  \\\n",
       "0  Baseline (SeasonalNaive-7)        none  100.566129  164.751355  24.294597   \n",
       "1              Best (AutoETS)        none   86.852207  153.463049  17.512230   \n",
       "\n",
       "         r2  \n",
       "0  0.976751  \n",
       "1  0.979828  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>feature_set</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>smape</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline (SeasonalNaive-7)</td>\n",
       "      <td>none</td>\n",
       "      <td>100.566129</td>\n",
       "      <td>164.751355</td>\n",
       "      <td>24.294597</td>\n",
       "      <td>0.976751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Best (AutoETS)</td>\n",
       "      <td>none</td>\n",
       "      <td>86.852207</td>\n",
       "      <td>153.463049</td>\n",
       "      <td>17.512230</td>\n",
       "      <td>0.979828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model feature_set         mae        rmse      smape  \\\n",
       "0  Baseline (SeasonalNaive-7)        none  100.566129  164.751355  24.294597   \n",
       "1              Best (AutoETS)        none   86.852207  153.463049  17.512230   \n",
       "\n",
       "         r2  \n",
       "0  0.976751  \n",
       "1  0.979828  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge predictions with actuals\n",
    "results_test = y_test.merge(fcst_baseline, on=[\"unique_id\", \"ds\"], how=\"left\")\n",
    "results_test = results_test.merge(fcst_best, on=[\"unique_id\", \"ds\"], how=\"left\")\n",
    "\n",
    "# Calculate metrics\n",
    "mae_baseline = mean_absolute_error(results_test[\"y\"], results_test[\"baseline_pred\"])\n",
    "rmse_baseline = root_mean_squared_error(results_test[\"y\"], results_test[\"baseline_pred\"])\n",
    "smape_baseline = np.mean(200 * np.abs(results_test[\"baseline_pred\"] - results_test[\"y\"]) / (np.abs(results_test[\"y\"]) + np.abs(results_test[\"baseline_pred\"]) + 1e-8))\n",
    "r2_baseline = r2_score(results_test[\"y\"], results_test[\"baseline_pred\"])\n",
    "\n",
    "mae_best = mean_absolute_error(results_test[\"y\"], results_test[\"best_pred\"])\n",
    "rmse_best = root_mean_squared_error(results_test[\"y\"], results_test[\"best_pred\"])\n",
    "smape_best = np.mean(200 * np.abs(results_test[\"best_pred\"] - results_test[\"y\"]) / (np.abs(results_test[\"y\"]) + np.abs(results_test[\"best_pred\"]) + 1e-8))\n",
    "r2_best = r2_score(results_test[\"y\"], results_test[\"best_pred\"])\n",
    "\n",
    "metrics = pd.DataFrame({\n",
    "    \"model\": [\"Baseline (SeasonalNaive-7)\", f\"Best ({best_model_name})\"],\n",
    "    \"feature_set\": [\"none\", best_feature],\n",
    "    \"mae\": [mae_baseline, mae_best],\n",
    "    \"rmse\": [rmse_baseline, rmse_best],\n",
    "    \"smape\": [smape_baseline, smape_best],\n",
    "    \"r2\": [r2_baseline, r2_best],\n",
    "})\n",
    "\n",
    "display(metrics)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ea22806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to ..\\data\\predictions\\test_predictions.parquet\n",
      "Saved metrics to ..\\data\\predictions\\test_metrics.parquet\n",
      "Saved best model config to ..\\data\\predictions\\best_model_config.parquet\n"
     ]
    }
   ],
   "source": [
    "# Save predictions and metrics\n",
    "PRED_DIR = Path(\"..\") / \"data\" / \"predictions\"\n",
    "PRED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save predictions\n",
    "results_test_pl = pl.from_pandas(results_test)\n",
    "pred_path = PRED_DIR / \"test_predictions.parquet\"\n",
    "results_test_pl.write_parquet(pred_path)\n",
    "print(f\"Saved predictions to {pred_path}\")\n",
    "\n",
    "# Save metrics\n",
    "metrics_pl = pl.from_pandas(metrics)\n",
    "metrics_path = PRED_DIR / \"test_metrics.parquet\"\n",
    "metrics_pl.write_parquet(metrics_path)\n",
    "print(f\"Saved metrics to {metrics_path}\")\n",
    "\n",
    "# Save best model configuration\n",
    "best_config = pd.DataFrame([{\n",
    "    \"model\": best_model_name,\n",
    "    \"feature_set\": best_feature,\n",
    "    \"params\": str(best_params),\n",
    "    \"used_exog\": used_exog,\n",
    "    \"val_mae\": best_combo[\"mae\"],\n",
    "    \"val_rmse\": best_combo[\"rmse\"],\n",
    "    \"val_smape\": best_combo[\"smape\"],\n",
    "    \"val_r2\": best_combo.get(\"r2\", np.nan),\n",
    "    \"test_mae\": mae_best,\n",
    "    \"test_rmse\": rmse_best,\n",
    "    \"test_smape\": smape_best,\n",
    "    \"test_r2\": r2_best,\n",
    "}])\n",
    "\n",
    "config_pl = pl.from_pandas(best_config)\n",
    "config_path = PRED_DIR / \"best_model_config.parquet\"\n",
    "config_pl.write_parquet(config_path)\n",
    "print(f\"Saved best model config to {config_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6737f552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                   model_name metrics  preditions\n",
       " 0  Baseline (SeasonalNaive-7)     mae  100.566129\n",
       " 1              Best (AutoETS)     mae   86.852207\n",
       " 2  Baseline (SeasonalNaive-7)    rmse  164.751355\n",
       " 3              Best (AutoETS)    rmse  153.463049\n",
       " 4  Baseline (SeasonalNaive-7)   smape   24.294597,\n",
       "                    model_name     unique_id         ds       y  preditions\n",
       " 0  Baseline (SeasonalNaive-7)  \"Bubble tea\" 2025-11-01  1148.0      1382.0\n",
       " 1  Baseline (SeasonalNaive-7)  \"Bubble tea\" 2025-11-02  1095.0      1316.0\n",
       " 2  Baseline (SeasonalNaive-7)  \"Bubble tea\" 2025-11-03  1097.0      1229.0\n",
       " 3  Baseline (SeasonalNaive-7)  \"Bubble tea\" 2025-11-04  1089.0      1429.0\n",
       " 4  Baseline (SeasonalNaive-7)  \"Bubble tea\" 2025-11-05  1218.0      1112.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_1 = pd.read_parquet(\"../data/predictions/best_model_config.parquet\")\n",
    "example_2 = pd.read_parquet(\"../data/predictions/test_metrics.parquet\")\n",
    "example_3 = pd.read_parquet(\"../data/predictions/test_predictions.parquet\")\n",
    "example_4 = pd.read_parquet(\"../data/predictions/test_metrics_long.parquet\")\n",
    "example_5 = pd.read_parquet(\"../data/predictions/test_predictions_long.parquet\")\n",
    "example_4.head(), example_5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7e3c21",
   "metadata": {},
   "source": [
    "## Long-format outputs\n",
    "Create long-format metrics and predictions and save to data/predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7227feb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved long metrics to ..\\data\\predictions\\test_metrics_long.parquet\n",
      "Saved long predictions to ..\\data\\predictions\\test_predictions_long.parquet\n"
     ]
    }
   ],
   "source": [
    "# Create long-format metrics (only numeric metrics)\n",
    "metric_cols = [\"mae\", \"rmse\", \"smape\", \"r2\"]\n",
    "metrics_long = (\n",
    "    metrics[[\"model\", *metric_cols]]\n",
    "    .melt(id_vars=[\"model\"], var_name=\"metrics\", value_name=\"preditions\")\n",
    "    .rename(columns={\"model\": \"model_name\"})\n",
    ")\n",
    "\n",
    "# Create long-format predictions\n",
    "baseline_long = results_test[[\"unique_id\", \"ds\", \"y\", \"baseline_pred\"]].rename(columns={\"baseline_pred\": \"preditions\"})\n",
    "baseline_long[\"model_name\"] = \"Baseline (SeasonalNaive-7)\"\n",
    "best_long = results_test[[\"unique_id\", \"ds\", \"y\", \"best_pred\"]].rename(columns={\"best_pred\": \"preditions\"})\n",
    "best_long[\"model_name\"] = f\"Best ({best_model_name})\"\n",
    "predictions_long = pd.concat([baseline_long, best_long], ignore_index=True)[[\"model_name\", \"unique_id\", \"ds\", \"y\", \"preditions\"]]\n",
    "\n",
    "# Save long-format files\n",
    "metrics_long_pl = pl.from_pandas(metrics_long)\n",
    "metrics_long_path = PRED_DIR / \"test_metrics_long.parquet\"\n",
    "metrics_long_pl.write_parquet(metrics_long_path)\n",
    "print(f\"Saved long metrics to {metrics_long_path}\")\n",
    "\n",
    "predictions_long_pl = pl.from_pandas(predictions_long)\n",
    "predictions_long_path = PRED_DIR / \"test_predictions_long.parquet\"\n",
    "predictions_long_pl.write_parquet(predictions_long_path)\n",
    "print(f\"Saved long predictions to {predictions_long_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "078ea0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>preditions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline (SeasonalNaive-7)</td>\n",
       "      <td>\"Bubble tea\"</td>\n",
       "      <td>2025-11-01</td>\n",
       "      <td>1148.0</td>\n",
       "      <td>1382.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline (SeasonalNaive-7)</td>\n",
       "      <td>\"Bubble tea\"</td>\n",
       "      <td>2025-11-02</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>1316.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baseline (SeasonalNaive-7)</td>\n",
       "      <td>\"Bubble tea\"</td>\n",
       "      <td>2025-11-03</td>\n",
       "      <td>1097.0</td>\n",
       "      <td>1229.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baseline (SeasonalNaive-7)</td>\n",
       "      <td>\"Bubble tea\"</td>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>1089.0</td>\n",
       "      <td>1429.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baseline (SeasonalNaive-7)</td>\n",
       "      <td>\"Bubble tea\"</td>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>1112.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>Best (AutoETS)</td>\n",
       "      <td>\"Tea\"</td>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>1239.0</td>\n",
       "      <td>1237.329451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>Best (AutoETS)</td>\n",
       "      <td>\"Tea\"</td>\n",
       "      <td>2025-11-28</td>\n",
       "      <td>1239.0</td>\n",
       "      <td>1170.729862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Best (AutoETS)</td>\n",
       "      <td>\"Tea\"</td>\n",
       "      <td>2025-11-29</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>1125.839810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Best (AutoETS)</td>\n",
       "      <td>\"Tea\"</td>\n",
       "      <td>2025-11-30</td>\n",
       "      <td>1331.0</td>\n",
       "      <td>1194.476400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Best (AutoETS)</td>\n",
       "      <td>\"Tea\"</td>\n",
       "      <td>2025-12-01</td>\n",
       "      <td>1527.0</td>\n",
       "      <td>1255.664828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>620 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model_name     unique_id         ds       y   preditions\n",
       "0    Baseline (SeasonalNaive-7)  \"Bubble tea\" 2025-11-01  1148.0  1382.000000\n",
       "1    Baseline (SeasonalNaive-7)  \"Bubble tea\" 2025-11-02  1095.0  1316.000000\n",
       "2    Baseline (SeasonalNaive-7)  \"Bubble tea\" 2025-11-03  1097.0  1229.000000\n",
       "3    Baseline (SeasonalNaive-7)  \"Bubble tea\" 2025-11-04  1089.0  1429.000000\n",
       "4    Baseline (SeasonalNaive-7)  \"Bubble tea\" 2025-11-05  1218.0  1112.000000\n",
       "..                          ...           ...        ...     ...          ...\n",
       "615              Best (AutoETS)         \"Tea\" 2025-11-27  1239.0  1237.329451\n",
       "616              Best (AutoETS)         \"Tea\" 2025-11-28  1239.0  1170.729862\n",
       "617              Best (AutoETS)         \"Tea\" 2025-11-29  1218.0  1125.839810\n",
       "618              Best (AutoETS)         \"Tea\" 2025-11-30  1331.0  1194.476400\n",
       "619              Best (AutoETS)         \"Tea\" 2025-12-01  1527.0  1255.664828\n",
       "\n",
       "[620 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fb4ffb",
   "metadata": {},
   "source": [
    "## Extend predictions to include December\n",
    "Generate additional daily predictions for December 2024 and append to existing predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e52d168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current predictions start: 2025-11-01 00:00:00\n",
      "Current predictions end: 2025-12-01 00:00:00\n",
      "\n",
      "Need 30 additional days to cover all of December\n",
      "\n",
      "✓ Extended predictions to 2025-12-31 00:00:00\n",
      "Total predictions: 610 rows\n",
      "Date range: 2025-11-01 00:00:00 to 2025-12-31 00:00:00\n",
      "Saved extended predictions to ..\\data\\predictions\\test_predictions_extended.parquet\n",
      "Saved extended long predictions to ..\\data\\predictions\\test_predictions_long_extended.parquet\n"
     ]
    }
   ],
   "source": [
    "# Check current prediction date range\n",
    "print(f\"Current predictions start: {results_test['ds'].min()}\")\n",
    "print(f\"Current predictions end: {results_test['ds'].max()}\")\n",
    "\n",
    "# Calculate days needed to reach end of December 2024\n",
    "last_pred_date = pd.to_datetime(results_test['ds'].max())\n",
    "december_end = pd.Timestamp('2025-12-31')\n",
    "\n",
    "if last_pred_date < december_end:\n",
    "    additional_days = (december_end - last_pred_date).days\n",
    "    print(f\"\\nNeed {additional_days} additional days to cover all of December\")\n",
    "    \n",
    "    # Calculate new total horizon\n",
    "    h_extended = h_test + additional_days\n",
    "    \n",
    "    # Generate extended predictions with baseline model\n",
    "    fcst_baseline_ext = sf_baseline.predict(h=h_extended)\n",
    "    baseline_col = [c for c in fcst_baseline_ext.columns if c not in (\"unique_id\", \"ds\")][0]\n",
    "    fcst_baseline_ext = fcst_baseline_ext.rename(columns={baseline_col: \"baseline_pred\"})\n",
    "    \n",
    "    # Generate extended predictions with best model\n",
    "    if best_model_name == \"RandomForestRegressor\":\n",
    "        # For RandomForest, we need to generate future features for December\n",
    "        # Get the full training data\n",
    "        train_full_extended = pd.concat([\n",
    "            splits[\"train\"].to_pandas(),\n",
    "            splits[\"val\"].to_pandas(),\n",
    "            splits[\"test\"].to_pandas()\n",
    "        ], ignore_index=True).sort_values([\"unique_id\", \"ds\"]).reset_index(drop=True)\n",
    "        \n",
    "        # Generate future dates for December\n",
    "        unique_ids = train_full_extended[\"unique_id\"].unique()\n",
    "        last_date = pd.to_datetime(train_full_extended['ds'].max())\n",
    "        future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), end=december_end, freq='D')\n",
    "        \n",
    "        # Create future dataframe with same features structure\n",
    "        future_rows = []\n",
    "        for uid in unique_ids:\n",
    "            for date in future_dates:\n",
    "                row = {\"unique_id\": uid, \"ds\": date}\n",
    "                # Add feature columns with default values or derived features\n",
    "                for col in feature_cols:\n",
    "                    if col in train_full_extended.columns:\n",
    "                        # Use most recent value or zero as placeholder\n",
    "                        row[col] = 0\n",
    "                future_rows.append(row)\n",
    "        \n",
    "        future_df = pd.DataFrame(future_rows).fillna(0)\n",
    "        \n",
    "        # Make predictions\n",
    "        cat_cols = [c for c in feature_cols if future_df[c].dtype == \"object\"]\n",
    "        future_X = pd.get_dummies(future_df[feature_cols], columns=cat_cols, drop_first=False)\n",
    "        \n",
    "        # Align columns with training data\n",
    "        train_df_check = y_train_val.merge(X_train_val, on=[\"unique_id\", \"ds\"], how=\"left\").fillna(0)\n",
    "        feature_cols_rf = [c for c in train_df_check.columns if c not in [\"unique_id\", \"ds\", \"y\"]]\n",
    "        train_X_check = pd.get_dummies(train_df_check[feature_cols_rf], drop_first=False)\n",
    "        \n",
    "        cols = sorted(set(train_X_check.columns) | set(future_X.columns))\n",
    "        future_X = future_X.reindex(columns=cols, fill_value=0)\n",
    "        \n",
    "        dec_preds = best_model.predict(future_X)\n",
    "        fcst_best_ext = future_df[[\"unique_id\", \"ds\"]].copy()\n",
    "        fcst_best_ext[\"best_pred\"] = dec_preds\n",
    "        \n",
    "        # Combine with existing predictions\n",
    "        fcst_best_ext = pd.concat([fcst_best, fcst_best_ext], ignore_index=True)\n",
    "    else:\n",
    "        fcst_best_ext = sf_best.predict(h=h_extended)\n",
    "        best_col = [c for c in fcst_best_ext.columns if c not in (\"unique_id\", \"ds\")][0]\n",
    "        fcst_best_ext = fcst_best_ext.rename(columns={best_col: \"best_pred\"})\n",
    "    \n",
    "    # Create extended results (note: we don't have actual 'y' values for December)\n",
    "    # Get unique IDs from existing results\n",
    "    unique_ids = results_test[\"unique_id\"].unique()\n",
    "    \n",
    "    # Create December rows with NaN for actual values\n",
    "    december_rows = []\n",
    "    for uid in unique_ids:\n",
    "        uid_baseline = fcst_baseline_ext[fcst_baseline_ext[\"unique_id\"] == uid]\n",
    "        uid_best = fcst_best_ext[fcst_best_ext[\"unique_id\"] == uid]\n",
    "        \n",
    "        for _, base_row in uid_baseline.iterrows():\n",
    "            if pd.to_datetime(base_row[\"ds\"]) > last_pred_date:\n",
    "                best_row = uid_best[uid_best[\"ds\"] == base_row[\"ds\"]]\n",
    "                if len(best_row) > 0:\n",
    "                    december_rows.append({\n",
    "                        \"unique_id\": uid,\n",
    "                        \"ds\": base_row[\"ds\"],\n",
    "                        \"y\": np.nan,  # No actual values for future\n",
    "                        \"baseline_pred\": base_row[\"baseline_pred\"],\n",
    "                        \"best_pred\": best_row[\"best_pred\"].values[0]\n",
    "                    })\n",
    "    \n",
    "    december_df = pd.DataFrame(december_rows)\n",
    "    \n",
    "    # Append December predictions to existing results\n",
    "    results_test_extended = pd.concat([results_test, december_df], ignore_index=True).sort_values([\"unique_id\", \"ds\"]).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"\\n✓ Extended predictions to {results_test_extended['ds'].max()}\")\n",
    "    print(f\"Total predictions: {len(results_test_extended)} rows\")\n",
    "    print(f\"Date range: {results_test_extended['ds'].min()} to {results_test_extended['ds'].max()}\")\n",
    "    \n",
    "    # Save extended predictions\n",
    "    results_extended_pl = pl.from_pandas(results_test_extended)\n",
    "    pred_extended_path = PRED_DIR / \"test_predictions_extended.parquet\"\n",
    "    results_extended_pl.write_parquet(pred_extended_path)\n",
    "    print(f\"Saved extended predictions to {pred_extended_path}\")\n",
    "    \n",
    "    # Update long-format predictions with December\n",
    "    baseline_long_ext = results_test_extended[[\"unique_id\", \"ds\", \"y\", \"baseline_pred\"]].rename(columns={\"baseline_pred\": \"preditions\"})\n",
    "    baseline_long_ext[\"model_name\"] = \"Baseline (SeasonalNaive-7)\"\n",
    "    best_long_ext = results_test_extended[[\"unique_id\", \"ds\", \"y\", \"best_pred\"]].rename(columns={\"best_pred\": \"preditions\"})\n",
    "    best_long_ext[\"model_name\"] = f\"Best ({best_model_name})\"\n",
    "    predictions_long_extended = pd.concat([baseline_long_ext, best_long_ext], ignore_index=True)[[\"model_name\", \"unique_id\", \"ds\", \"y\", \"preditions\"]]\n",
    "    \n",
    "    # Save extended long-format predictions\n",
    "    predictions_long_ext_pl = pl.from_pandas(predictions_long_extended)\n",
    "    predictions_long_ext_path = PRED_DIR / \"test_predictions_long_extended.parquet\"\n",
    "    predictions_long_ext_pl.write_parquet(predictions_long_ext_path)\n",
    "    print(f\"Saved extended long predictions to {predictions_long_ext_path}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"\\nPredictions already cover December (end date: {last_pred_date})\")\n",
    "    results_test_extended = results_test\n",
    "    predictions_long_extended = predictions_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a672220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>preditions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline (SeasonalNaive-7)</td>\n",
       "      <td>\"Bubble tea\"</td>\n",
       "      <td>2025-11-01</td>\n",
       "      <td>1148.0</td>\n",
       "      <td>1382.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline (SeasonalNaive-7)</td>\n",
       "      <td>\"Bubble tea\"</td>\n",
       "      <td>2025-11-02</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>1316.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baseline (SeasonalNaive-7)</td>\n",
       "      <td>\"Bubble tea\"</td>\n",
       "      <td>2025-11-03</td>\n",
       "      <td>1097.0</td>\n",
       "      <td>1229.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baseline (SeasonalNaive-7)</td>\n",
       "      <td>\"Bubble tea\"</td>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>1089.0</td>\n",
       "      <td>1429.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baseline (SeasonalNaive-7)</td>\n",
       "      <td>\"Bubble tea\"</td>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>1112.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>Best (AutoETS)</td>\n",
       "      <td>\"Tea\"</td>\n",
       "      <td>2025-12-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1125.839810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>Best (AutoETS)</td>\n",
       "      <td>\"Tea\"</td>\n",
       "      <td>2025-12-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1194.476400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>Best (AutoETS)</td>\n",
       "      <td>\"Tea\"</td>\n",
       "      <td>2025-12-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1255.664828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>Best (AutoETS)</td>\n",
       "      <td>\"Tea\"</td>\n",
       "      <td>2025-12-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1254.233791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>Best (AutoETS)</td>\n",
       "      <td>\"Tea\"</td>\n",
       "      <td>2025-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1253.418165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1220 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model_name     unique_id         ds       y   preditions\n",
       "0     Baseline (SeasonalNaive-7)  \"Bubble tea\" 2025-11-01  1148.0  1382.000000\n",
       "1     Baseline (SeasonalNaive-7)  \"Bubble tea\" 2025-11-02  1095.0  1316.000000\n",
       "2     Baseline (SeasonalNaive-7)  \"Bubble tea\" 2025-11-03  1097.0  1229.000000\n",
       "3     Baseline (SeasonalNaive-7)  \"Bubble tea\" 2025-11-04  1089.0  1429.000000\n",
       "4     Baseline (SeasonalNaive-7)  \"Bubble tea\" 2025-11-05  1218.0  1112.000000\n",
       "...                          ...           ...        ...     ...          ...\n",
       "1215              Best (AutoETS)         \"Tea\" 2025-12-27     NaN  1125.839810\n",
       "1216              Best (AutoETS)         \"Tea\" 2025-12-28     NaN  1194.476400\n",
       "1217              Best (AutoETS)         \"Tea\" 2025-12-29     NaN  1255.664828\n",
       "1218              Best (AutoETS)         \"Tea\" 2025-12-30     NaN  1254.233791\n",
       "1219              Best (AutoETS)         \"Tea\" 2025-12-31     NaN  1253.418165\n",
       "\n",
       "[1220 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_long_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e67f2be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of extended predictions (including December):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>baseline_pred</th>\n",
       "      <th>best_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>\"Tea\"</td>\n",
       "      <td>2025-12-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1415.0</td>\n",
       "      <td>1255.664828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>\"Tea\"</td>\n",
       "      <td>2025-12-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>1254.233791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>\"Tea\"</td>\n",
       "      <td>2025-12-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>1253.418165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>\"Tea\"</td>\n",
       "      <td>2025-12-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1286.0</td>\n",
       "      <td>1237.329451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>\"Tea\"</td>\n",
       "      <td>2025-12-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>1170.729862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>\"Tea\"</td>\n",
       "      <td>2025-12-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>1125.839810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>\"Tea\"</td>\n",
       "      <td>2025-12-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1282.0</td>\n",
       "      <td>1194.476400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>\"Tea\"</td>\n",
       "      <td>2025-12-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1415.0</td>\n",
       "      <td>1255.664828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>\"Tea\"</td>\n",
       "      <td>2025-12-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>1254.233791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>\"Tea\"</td>\n",
       "      <td>2025-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>1253.418165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    unique_id         ds   y  baseline_pred    best_pred\n",
       "600     \"Tea\" 2025-12-22 NaN         1415.0  1255.664828\n",
       "601     \"Tea\" 2025-12-23 NaN         1368.0  1254.233791\n",
       "602     \"Tea\" 2025-12-24 NaN         1274.0  1253.418165\n",
       "603     \"Tea\" 2025-12-25 NaN         1286.0  1237.329451\n",
       "604     \"Tea\" 2025-12-26 NaN         1110.0  1170.729862\n",
       "605     \"Tea\" 2025-12-27 NaN         1265.0  1125.839810\n",
       "606     \"Tea\" 2025-12-28 NaN         1282.0  1194.476400\n",
       "607     \"Tea\" 2025-12-29 NaN         1415.0  1255.664828\n",
       "608     \"Tea\" 2025-12-30 NaN         1368.0  1254.233791\n",
       "609     \"Tea\" 2025-12-31 NaN         1274.0  1253.418165"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions by month:\n",
      "month\n",
      "2025-11    300\n",
      "2025-12    310\n",
      "Freq: M, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display sample of extended predictions\n",
    "print(\"\\nSample of extended predictions (including December):\")\n",
    "display(results_test_extended.tail(10))\n",
    "print(f\"\\nPredictions by month:\")\n",
    "results_test_extended['month'] = pd.to_datetime(results_test_extended['ds']).dt.to_period('M')\n",
    "print(results_test_extended.groupby('month').size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
